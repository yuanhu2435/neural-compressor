<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Examples &mdash; Intel® Neural Compressor  documentation</title><link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> Intel® Neural Compressor
          </a>
              <div class="version">
                1.14.2
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../README.html">Intel® Neural Compressor</a></li>
<li class="toctree-l1"><a class="reference internal" href="../docs/examples_readme.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api-documentation/apis.html">APIs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../docs/doclist.html">Developer Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../docs/releases_info.html">Release</a></li>
<li class="toctree-l1"><a class="reference internal" href="../docs/contributions.html">Contribution Guidelines</a></li>
<li class="toctree-l1"><a class="reference internal" href="../docs/legal_information.html">Legal Information</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/intel/neural-compressor">Intel® Neural Compressor repository</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Intel® Neural Compressor</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a></li>
      <li class="breadcrumb-item active">Examples</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/examples/README.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <div class="section" id="examples">
<h1>Examples<a class="headerlink" href="#examples" title="Permalink to this headline">¶</a></h1>
<p>Intel® Neural Compressor validated examples with multiple compression techniques, including quantization, pruning, knowledge distillation and orchestration. Part of the validated cases can be found in the example tables, and the release data is available <a class="reference internal" href="../docs/validated_model_list.html"><span class="doc">here</span></a>.</p>
<div class="section" id="helloworld-examples">
<h2>Helloworld Examples<a class="headerlink" href="#helloworld-examples" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p><a class="reference external" href="https://github.com/intel/neural-compressor/tree/0a8ab0c91cdb41d6da70c55628fb2d2b500238dd/examples/helloworld/tf_example1">tf_example1</a>: quantize with built-in dataloader and metric.</p></li>
<li><p><a class="reference external" href="https://github.com/intel/neural-compressor/tree/0a8ab0c91cdb41d6da70c55628fb2d2b500238dd/examples/helloworld/tf_example2">tf_example2</a>: quantize keras model with customized metric and dataloader.</p></li>
<li><p><a class="reference external" href="https://github.com/intel/neural-compressor/tree/0a8ab0c91cdb41d6da70c55628fb2d2b500238dd/examples/helloworld/tf_example3">tf_example3</a>: quantize slim model.</p></li>
<li><p><a class="reference external" href="https://github.com/intel/neural-compressor/tree/0a8ab0c91cdb41d6da70c55628fb2d2b500238dd/examples/helloworld/tf_example4">tf_example4</a>: quantize checkpoint with dummy dataloader.</p></li>
<li><p><a class="reference external" href="https://github.com/intel/neural-compressor/tree/0a8ab0c91cdb41d6da70c55628fb2d2b500238dd/examples/helloworld/tf_example5">tf_example5</a>: config performance and accuracy measurement.</p></li>
<li><p><a class="reference external" href="https://github.com/intel/neural-compressor/tree/0a8ab0c91cdb41d6da70c55628fb2d2b500238dd/examples/helloworld/tf_example6">tf_example6</a>: use default user-facing APIs to quantize a pb model.</p></li>
<li><p><a class="reference external" href="https://github.com/intel/neural-compressor/tree/0a8ab0c91cdb41d6da70c55628fb2d2b500238dd/examples/helloworld/tf_example7">tf_example7</a>: enable quantization and benchmark with python-flavor config.</p></li>
<li><p><a class="reference external" href="https://github.com/intel/neural-compressor/tree/0a8ab0c91cdb41d6da70c55628fb2d2b500238dd/examples/helloworld/tf_example8">tf_example8</a>: quantize with pure python API.</p></li>
</ul>
</div>
<div class="section" id="notebook-examples">
<h2>Notebook Examples<a class="headerlink" href="#notebook-examples" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p><a class="reference external" href="https://github.com/intel/neural-compressor/tree/0a8ab0c91cdb41d6da70c55628fb2d2b500238dd/examples/notebook/bert_mini_distillation">BERT Mini SST2 performance boost with INC</a>: train a BERT-Mini model on SST-2 dataset through distillation, and leverage quantization to accelerate the inference while maintaining the accuracy using Intel® Neural Compressor.</p></li>
<li><p><a class="reference external" href="https://github.com/intel/neural-compressor/tree/0a8ab0c91cdb41d6da70c55628fb2d2b500238dd/examples/notebook/perf_fp32_int8_tf">Performance of FP32 Vs. INT8 ResNet50 Model</a>: compare existed FP32 &amp; INT8 ResNet50 model directly.</p></li>
<li><p><a class="reference external" href="https://github.com/intel/neural-compressor/tree/0a8ab0c91cdb41d6da70c55628fb2d2b500238dd/examples/notebook/pytorch/alexnet_fashion_mnist">Intel® Neural Compressor Sample for PyTorch*</a>: an End-To-End pipeline to build up a CNN model by PyTorch to recognize fashion image and speed up AI model by Intel® Neural Compressor.</p></li>
<li><p><a class="reference external" href="https://github.com/intel/neural-compressor/tree/0a8ab0c91cdb41d6da70c55628fb2d2b500238dd/examples/notebook/tensorflow/alexnet_mnist">Intel® Neural Compressor Sample for TensorFlow*</a>: an End-To-End pipeline to build up a CNN model by TensorFlow to recognize handwriting number and speed up AI model by Intel® Neural Compressor:</p></li>
</ul>
</div>
</div>
<div class="section" id="tensorflow-examples">
<h1>TensorFlow Examples<a class="headerlink" href="#tensorflow-examples" title="Permalink to this headline">¶</a></h1>
<div class="section" id="quantization">
<h2>Quantization<a class="headerlink" href="#quantization" title="Permalink to this headline">¶</a></h2>
<table>
<thead>
  <tr>
    <th>Model</th>
    <th>Domain</th>
    <th>Approach</th>
    <th>Examples</th>
  </tr>
</thead>
<tbody>
  <tr>
    <td>ResNet50 V1.0</td>
    <td>Image Recognition</td>
    <td>Post-Training Static Quantization</td>
    <td><a href="./tensorflow/image_recognition/tensorflow_models/quantization/ptq">pb</a></td>
  </tr>
  <tr>
    <td>ResNet50 V1.5</td>
    <td>Image Recognition</td>
    <td>Post-Training Static Quantization</td>
    <td><a href="./tensorflow/image_recognition/tensorflow_models/quantization/ptq">pb</a></td>
  </tr>
  <tr>
    <td>ResNet101</td>
    <td>Image Recognition</td>
    <td>Post-Training Static Quantization</td>
    <td><a href="./tensorflow/image_recognition/tensorflow_models/quantization/ptq">pb</a></td>
  </tr>
  <tr>
    <td>MobileNet V1</td>
    <td>Image Recognition</td>
    <td>Post-Training Static Quantization</td>
    <td><a href="./tensorflow/image_recognition/tensorflow_models/quantization/ptq">pb</a> / <a href="./tensorflow/image_recognition/SavedModel/quantization/ptq">SavedModel</a></td>
  </tr>
  <tr>
    <td>MobileNet V2</td>
    <td>Image Recognition</td>
    <td>Post-Training Static Quantization</td>
    <td><a href="./tensorflow/image_recognition/tensorflow_models/quantization/ptq">pb</a>  / <a href="./tensorflow/image_recognition/SavedModel/quantization/ptq">SavedModel</a> / <a href="./tensorflow/image_recognition/keras_models/mobilenet_v2/quantization/ptq">keras</a></td>
  </tr>
  <tr>
    <td>MobileNet V3</td>
    <td>Image Recognition</td>
    <td>Post-Training Static Quantization</td>
    <td><a href="./tensorflow/image_recognition/tensorflow_models/quantization/ptq">pb</a></td>
  </tr>
  <tr>
    <td>Inception V1</td>
    <td>Image Recognition</td>
    <td>Post-Training Static Quantization</td>
    <td><a href="./tensorflow/image_recognition/tensorflow_models/quantization/ptq">pb</a></td>
  </tr>
  <tr>
    <td>Inception V2</td>
    <td>Image Recognition</td>
    <td>Post-Training Static Quantization</td>
    <td><a href="./tensorflow/image_recognition/tensorflow_models/quantization/ptq">pb</a></td>
  </tr>
  <tr>
    <td>Inception V3</td>
    <td>Image Recognition</td>
    <td>Post-Training Static Quantization</td>
    <td><a href="./tensorflow/image_recognition/tensorflow_models/quantization/ptq">pb</a></td>
  </tr>
  <tr>
    <td>Inception V4</td>
    <td>Image Recognition</td>
    <td>Post-Training Static Quantization</td>
    <td><a href="./tensorflow/image_recognition/tensorflow_models/quantization/ptq">pb</a></td>
  </tr>
  <tr>
    <td>Inception ResNet V2</td>
    <td>Image Recognition</td>
    <td>Post-Training Static Quantization</td>
    <td><a href="./tensorflow/image_recognition/tensorflow_models/quantization/ptq">pb</a></td>
  </tr>
  <tr>
    <td>VGG16</td>
    <td>Image Recognition</td>
    <td>Post-Training Static Quantization</td>
    <td><a href="./tensorflow/image_recognition/tensorflow_models/quantization/ptq">pb</a> / <a href="./tensorflow/image_recognition/keras_models/vgg16/quantization/ptq">keras</a></td>
  </tr>
  <tr>
    <td>VGG19</td>
    <td>Image Recognition</td>
    <td>Post-Training Static Quantization</td>
    <td><a href="./tensorflow/image_recognition/tensorflow_models/quantization/ptq">pb</a> / <a href="./tensorflow/image_recognition/keras_models/vgg19/quantization/ptq">keras</a></td>
  </tr>
  <tr>
    <td>ResNet V2 50</td>
    <td>Image Recognition</td>
    <td>Post-Training Static Quantization</td>
    <td><a href="./tensorflow/image_recognition/tensorflow_models/quantization/ptq">pb</a> / <a href="./tensorflow/image_recognition/keras_models/resnetv2_50/quantization/ptq">keras</a></td>
  </tr>
  <tr>
    <td>ResNet V2 101</td>
    <td>Image Recognition</td>
    <td>Post-Training Static Quantization</td>
    <td><a href="./tensorflow/image_recognition/tensorflow_models/quantization/ptq">pb</a> / <a href="./tensorflow/image_recognition/keras_models/resnetv2_101/quantization/ptq">keras</a></td>
  </tr>
  <tr>
    <td>ResNet V2 152</td>
    <td>Image Recognition</td>
    <td>Post-Training Static Quantization</td>
    <td><a href="./tensorflow/image_recognition/tensorflow_models/quantization/ptq">pb</a></td>
  </tr>
  <tr>
    <td>DenseNet121</td>
    <td>Image Recognition</td>
    <td>Post-Training Static Quantization</td>
    <td><a href="./tensorflow/image_recognition/tensorflow_models/quantization/ptq">pb</a></td>
  </tr>
  <tr>
    <td>DenseNet161</td>
    <td>Image Recognition</td>
    <td>Post-Training Static Quantization</td>
    <td><a href="./tensorflow/image_recognition/tensorflow_models/quantization/ptq">pb</a></td>
  </tr>
  <tr>
    <td>DenseNet169</td>
    <td>Image Recognition</td>
    <td>Post-Training Static Quantization</td>
    <td><a href="./tensorflow/image_recognition/tensorflow_models/quantization/ptq">pb</a></td>
  </tr>
  <tr>
    <td>EfficientNet B0</td>
    <td>Image Recognition</td>
    <td>Post-Training Static Quantization</td>
    <td><a href="./tensorflow/image_recognition/tensorflow_models/quantization/ptq">ckpt</a></td>
  </tr>
  <tr>
    <td>MNIST </td>
    <td>Image Recognition</td>
    <td>Quantization-Aware Training</td>
    <td><a href="./tensorflow/image_recognition/keras_models/mnist/quantization/qat">keras</a></td>
  </tr>
  <tr>
    <td>ResNet50</td>
    <td>Image Recognition</td>
    <td>Post-Training Static Quantization</td>
    <td><a href="./tensorflow/image_recognition/keras_models/resnet50/quantization/ptq">keras</a></td>
  </tr>
  <tr>
    <td>ResNet50 Fashion</td>
    <td>Image Recognition</td>
    <td>Post-Training Static Quantization</td>
    <td><a href="./tensorflow/image_recognition/keras_models/resnet50_fashion/quantization/ptq">keras</a></td>
  </tr>
  <tr>
    <td>ResNet101</td>
    <td>Image Recognition</td>
    <td>Post-Training Static Quantization</td>
    <td><a href="./tensorflow/image_recognition/keras_models/resnet101/quantization/ptq">keras</a></td>
  </tr>
  <tr>
    <td>Inception V3</td>
    <td>Image Recognition</td>
    <td>Post-Training Static Quantization</td>
    <td><a href="./tensorflow/image_recognition/keras_models/inception_v3/quantization/ptq">keras</a></td>
  </tr>
  <tr>
    <td>Inception Resnet V2</td>
    <td>Image Recognition</td>
    <td>Post-Training Static Quantization</td>
    <td><a href="./tensorflow/image_recognition/keras_models/inception_resnet_v2/quantization/ptq">keras</a></td>
  </tr>
  <tr>
    <td>Xception</td>
    <td>Image Recognition</td>
    <td>Post-Training Static Quantization</td>
    <td><a href="./tensorflow/image_recognition/keras_models/xception/quantization/ptq">keras</a></td>
  </tr>
  <tr>
    <td>ResNet V2</td>
    <td>Image Recognition</td>
    <td>Quantization-Aware Training</td>
    <td><a href="./tensorflow/image_recognition/resnet_v2/quantization/qat">keras</a> </td>
  </tr>
  <tr>
    <td>EfficientNet V2 B0</td>
    <td>Image Recognition</td>
    <td>Post-Training Static Quantization</td>
    <td><a href="./tensorflow/image_recognition/SavedModel/quantization/ptq">SavedModel</a></td>
  </tr>
  <tr>
    <td>BERT base MRPC</td>
    <td>Natural Language Processing</td>
    <td>Post-Training Static Quantization</td>
    <td><a href="./tensorflow/nlp/bert_base_mrpc/quantization/ptq">ckpt</a></td>
  </tr>
  <tr>
    <td>BERT large SQuAD (Model Zoo)</td>
    <td>Natural Language Processing</td>
    <td>Post-Training Static Quantization</td>
    <td><a href="./tensorflow/nlp/bert_large_squad_model_zoo/quantization/ptq">pb</a></td>
  </tr>
  <tr>
    <td>BERT large SQuAD</td>
    <td>Natural Language Processing</td>
    <td>Post-Training Static Quantization</td>
    <td><a href="./tensorflow/nlp/bert_large_squad/quantization/ptq">pb</a></td>
  </tr>
  <tr>
    <td>Transformer LT</td>
    <td>Natural Language Processing</td>
    <td>Post-Training Static Quantization</td>
    <td><a href="./tensorflow/nlp/transformer_lt/quantization/ptq">pb</a></td>
  </tr>
  <tr>
    <td>SSD ResNet50 V1</td>
    <td>Object Detection</td>
    <td>Post-Training Static Quantization</td>
    <td><a href="./tensorflow/object_detection/tensorflow_models/quantization/ptq">pb</a> / <a href="./tensorflow/object_detection/tensorflow_models/quantization/ptq">ckpt</a></td>
  </tr>
  <tr>
    <td>SSD MobileNet V1</td>
    <td>Object Detection</td>
    <td>Post-Training Static Quantization</td>
    <td><a href="./tensorflow/object_detection/tensorflow_models/quantization/ptq">pb</a> / <a href="./tensorflow/object_detection/tensorflow_models/quantization/ptq">ckpt</a></td>
  </tr>
  <tr>
    <td>Faster R-CNN Inception ResNet V2</td>
    <td>Object Detection</td>
    <td>Post-Training Static Quantization</td>
    <td><a href="./tensorflow/object_detection/tensorflow_models/quantization/ptq">pb</a> / <a href="./tensorflow/object_detection/tensorflow_models/quantization/ptq">SavedModel</a></td>
  </tr>
  <tr>
    <td>Faster R-CNN ResNet101</td>
    <td>Object Detection</td>
    <td>Post-Training Static Quantization</td>
    <td><a href="./tensorflow/object_detection/tensorflow_models/quantization/ptq">pb</a> / <a href="./tensorflow/object_detection/tensorflow_models/quantization/ptq">SavedModel</a></td>
  </tr>
  <tr>
    <td>Faster R-CNN ResNet50</td>
    <td>Object Detection</td>
    <td>Post-Training Static Quantization</td>
    <td><a href="./tensorflow/object_detection/tensorflow_models/quantization/ptq">pb</a></td>
  </tr>
  <tr>
    <td>Mask R-CNN Inception V2</td>
    <td>Object Detection</td>
    <td>Post-Training Static Quantization</td>
    <td><a href="./tensorflow/object_detection/tensorflow_models/quantization/ptq">pb</a> / <a href="./tensorflow/object_detection/tensorflow_models/quantization/ptq">ckpt</a></td>
  </tr>
  <tr>
    <td>SSD ResNet34</td>
    <td>Object Detection</td>
    <td>Post-Training Static Quantization</td>
    <td><a href="./tensorflow/object_detection/tensorflow_models/quantization/ptq">pb</a></td>
  </tr>
  <tr>
    <td>YOLOv3</td>
    <td>Object Detection</td>
    <td>Post-Training Static Quantization</td>
    <td><a href="./tensorflow/object_detection/yolo_v3/quantization/ptq">pb</a></td>
  </tr>
  <tr>
    <td>Wide & Deep</td>
    <td>Recommendation</td>
    <td>Post-Training Static Quantization</td>
    <td><a href="./tensorflow/recommendation/wide_deep_large_ds/quantization/ptq">pb</a></td>
  </tr>
  <tr>
    <td>Arbitrary Style Transfer</td>
    <td>Style Transfer</td>
    <td>Post-Training Static Quantization</td>
    <td><a href="./tensorflow/style_transfer/arbitrary_style_transfer/quantization/ptq">ckpt</a></td>
  </tr>
</tbody>
</table></div>
<div class="section" id="pruning">
<h2>Pruning<a class="headerlink" href="#pruning" title="Permalink to this headline">¶</a></h2>
<table>
<thead>
  <tr>
    <th>Model</th>
    <th>Domain</th>
    <th>Pruning Type </th>
    <th>Approach </th>
    <th>Examples</th>
  </tr>
</thead>
<tbody>
  <tr>
    <td>Inception V3</td>
    <td>Image Recognition</td>
    <td>Unstructured</td>
    <td>Magnitude</td>
    <td><a href="./tensorflow/image_recognition/inception_v3/pruning/magnitude">pb</a></td>
  </tr>
  <tr>
    <td>ResNet V2</td>
    <td>Image Recognition</td>
    <td>Unstructured</td>
    <td>Magnitude</td>
    <td><a href="./tensorflow/image_recognition/resnet_v2/pruning/magnitude">pb</a></td>
  </tr>
  <tr>
    <td>ViT</td>
    <td>Image Recognition</td>
    <td>Unstructured</td>
    <td>Magnitude</td>
    <td><a href="./tensorflow/image_recognition/ViT/pruning/magnitude">ckpt</a></td>
  </tr>
</tbody>
</table></div>
<div class="section" id="distillation">
<h2>Distillation<a class="headerlink" href="#distillation" title="Permalink to this headline">¶</a></h2>
<table>
<thead>
  <tr>
    <th>Student Model</th>
    <th>Teacher Model</th>
    <th>Domain</th>
    <th>Examples</th>
  </tr>
</thead>
<tbody>
  <tr>
    <td>MobileNet</td>
    <td>DenseNet201</td>
    <td>Image Recognition</td>
    <td><a href="./tensorflow/image_recognition/tensorflow_models/distillation">pb</a></td>
  </tr>
</tbody>
</table></div>
</div>
<div class="section" id="pytorch-examples">
<h1>PyTorch  Examples<a class="headerlink" href="#pytorch-examples" title="Permalink to this headline">¶</a></h1>
<div class="section" id="id1">
<h2>Quantization<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h2>
<table>
<thead>
  <tr>
    <th>Model</th>
    <th>Domain</th>
    <th>Approach </th>
    <th>Examples</th>
  </tr>
</thead>
<tbody>
  <tr>
    <td>ResNet18</td>
    <td>Image Recognition</td>
    <td>Post-Training Static Quantization</td>
    <td><a href="./pytorch/image_recognition/torchvision_models/quantization/ptq/cpu/eager">eager</a> / <a href="./pytorch/image_recognition/torchvision_models/quantization/ptq/cpu/fx">fx</a> / <a href="./pytorch/image_recognition/torchvision_models/quantization/ptq/cpu/ipex">ipex</a></td>
  </tr>
  <tr>
    <td>ResNet18</td>
    <td>Image Recognition</td>
    <td>Quantization-Aware Training</td>
    <td><a href="./pytorch/image_recognition/torchvision_models/quantization/qat/eager">eager</a> / <a href="./pytorch/image_recognition/torchvision_models/quantization/qat/fx">fx</a></td>
  </tr>
  <tr>
    <td>ResNet50</td>
    <td>Image Recognition</td>
    <td>Post-Training Static Quantization</td>
    <td><a href="./pytorch/image_recognition/torchvision_models/quantization/ptq/cpu/eager">eager</a> / <a href="./pytorch/image_recognition/torchvision_models/quantization/ptq/cpu/ipex">ipex</a></td>
  </tr>
  <tr>
    <td>ResNet50</td>
    <td>Image Recognition</td>
    <td>Quantization-Aware Training</td>
    <td><a href="./pytorch/image_recognition/torchvision_models/quantization/qat/eager">eager</a></td>
  </tr>
  <tr>
    <td>ResNeXt101_32x16d_wsl</td>
    <td>Image Recognition</td>
    <td>Post-Training Static Quantization</td>
    <td><a href="./pytorch/image_recognition/torchvision_models/quantization/ptq/cpu/ipex">ipex</a></td>
  </tr>
  <tr>
    <td>ResNeXt101_32x8d</td>
    <td>Image Recognition</td>
    <td>Post-Training Static Quantization</td>
    <td><a href="./pytorch/image_recognition/torchvision_models/quantization/ptq/cpu/eager">eager</a></td>
  </tr>
  <tr>
    <td>Se_ResNeXt50_32x4d</td>
    <td>Image Recognition</td>
    <td>Post-Training Static Quantization</td>
    <td><a href="./pytorch/image_recognition/torchvision_models/quantization/ptq/cpu/eager">eager</a></td>
  </tr>
  <tr>
    <td>Inception V3</td>
    <td>Image Recognition</td>
    <td>Post-Training Static Quantization</td>
    <td><a href="./pytorch/image_recognition/torchvision_models/quantization/ptq/cpu/eager">eager</a></td>
  </tr>
  <tr>
    <td>MobileNet V2</td>
    <td>Image Recognition</td>
    <td>Post-Training Static Quantization</td>
    <td><a href="./pytorch/image_recognition/torchvision_models/quantization/ptq/cpu/eager">eager</a></td>
  </tr>
  <tr>
    <td>PeleeNet</td>
    <td>Image Recognition</td>
    <td>Post-Training Static Quantization</td>
    <td><a href="./pytorch/image_recognition/peleenet/quantization/ptq/eager">eager</a></td>
  </tr>
  <tr>
    <td>ResNeSt50</td>
    <td>Image Recognition</td>
    <td>Post-Training Static Quantization</td>
    <td><a href="./pytorch/image_recognition/resnest/quantization/ptq/eager">eager</a></td>
  </tr>
  <tr>
    <td>3D-UNet</td>
    <td>Image Recognition</td>
    <td>Post-Training Static Quantization</td>
    <td><a href="./pytorch/image_recognition/3d-unet/quantization/ptq/eager">eager</a></td>
  </tr>
  <tr>
    <td>SSD ResNet34</td>
    <td>Object Detection</td>
    <td>Post-Training Static Quantization</td>
    <td><a href="./pytorch/object_detection/ssd_resnet34/quantization/ptq/fx">fx</a> / <a href="./pytorch/object_detection/ssd_resnet34/quantization/ptq/ipex">ipex</a></td>
  </tr>
  <tr>
    <td>Mask R-CNN</td>
    <td>Object Detection</td>
    <td>Post-Training Static Quantization</td>
    <td><a href="./pytorch/object_detection/maskrcnn/quantization/ptq/fx">fx</a></td>
  </tr>
  <tr>
    <td>YOLOv3</td>
    <td>Object Detection</td>
    <td>Post-Training Static Quantization</td>
    <td><a href="./pytorch/object_detection/yolo_v3/quantization/ptq/eager">eager</a></td>
  </tr>
  <tr>
    <td>DLRM</td>
    <td>Recommendation</td>
    <td>Post-Training Static Quantization</td>
    <td><a href="./pytorch/recommendation/dlrm/quantization/ptq/eager">eager</a> / <a href="./pytorch/recommendation/dlrm/quantization/ptq/ipex">ipex</a> / <a href="./pytorch/recommendation/dlrm/quantization/ptq/fx">fx</a></td>
  </tr>
  <tr>
    <td>RNN-T</td>
    <td>Speech Recognition</td>
    <td>Post-Training Dynamic / Static Quantization</td>
    <td><a href="./pytorch/speech_recognition/rnnt/quantization/ptq_dynamic/eager">eager</a> </td>
  </tr>
  <tr>
    <td>Wav2Vec2</td>
    <td>Speech Recognition</td>
    <td>Post-Training Dynamic Quantization</td>
    <td><a href="./pytorch/speech_recognition/torchaudio_models/quantization/ptq_dynamic/eager">eager</a></td>
  </tr>
  <tr>
    <td>HuBERT</td>
    <td>Speech Recognition</td>
    <td>Post-Training Dynamic Quantization</td>
    <td><a href="./pytorch/speech_recognition/torchaudio_models/quantization/ptq_dynamic/eager">eager</a></td>
  </tr>
  <tr>
    <td>BlendCNN</td>
    <td>Natural Language Processing</td>
    <td>Post-Training Static Quantization</td>
    <td><a href="./pytorch/nlp/blendcnn/quantization/ptq/eager">eager</a></td>
  </tr>
  <tr>
    <td>bert-large-uncased-whole-word-masking-finetuned-squad</td>
    <td>Natural Language Processing</td>
    <td>Post-Training Static Quantization</td>
    <td><a href="./pytorch/nlp/huggingface_models/text-classification/quantization/ptq_static/fx">fx</a> / <a href="./pytorch/nlp/huggingface_models/question-answering/quantization/ptq_static/ipex">ipex</a></td>
  </tr>
    <tr>
    <td>distilbert-base-uncased-distilled-squad</td>
    <td>Natural Language Processing</td>
    <td>Post-Training Static Quantization</td>
    <td><a href="./pytorch/nlp/huggingface_models/question-answering/quantization/ptq_static/ipex">ipex</a></td>
  </tr>
  <tr>
    <td>t5-small</td>
    <td>Natural Language Processing</td>
    <td>Post-Training Dynamic Quantization</td>
    <td><a href="./pytorch/nlp/huggingface_models/translation/quantization/ptq_dynamic/eager">eager</a></td>
  </tr>
  <tr>
    <td>Helsinki-NLP/opus-mt-en-ro</td>
    <td>Natural Language Processing</td>
    <td>Post-Training Dynamic Quantization</td>
    <td><a href="./pytorch/nlp/huggingface_models/translation/quantization/ptq_dynamic/eager">eager</a></td>
  </tr>
  <tr>
    <td>lvwerra/pegasus-samsum</td>
    <td>Natural Language Processing</td>
    <td>Post-Training Dynamic Quantization</td>
    <td><a href="./pytorch/nlp/huggingface_models/summarization/quantization/ptq_dynamic/eager">eager</a></td>
  </tr>
</tbody>
</table></div>
<div class="section" id="id2">
<h2>Pruning<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h2>
<table>
<thead>
  <tr>
    <th>Model</th>
    <th>Domain</th>
    <th>Pruning Type </th>
    <th>Approach</th>
    <th>Examples</th>
  </tr>
</thead>
<tbody>
  <tr>
    <td>ResNet18</td>
    <td>Image Recognition</td>
    <td>Unstructured</td>
    <td>Magnitude</td>
    <td><a href="./pytorch/image_recognition/torchvision_models/pruning/magnitude/eager">eager</a></td>
  </tr>
  <tr>
    <td>ResNet34</td>
    <td>Image Recognition</td>
    <td>Unstructured</td>
    <td>Magnitude</td>
    <td><a href="./pytorch/image_recognition/torchvision_models/pruning/magnitude/eager">eager</a></td>
  </tr>
  <tr>
    <td>ResNet50</td>
    <td>Image Recognition</td>
    <td>Unstructured</td>
    <td>Magnitude</td>
    <td><a href="./pytorch/image_recognition/torchvision_models/pruning/magnitude/eager">eager</a></td>
  </tr>
  <tr>
    <td>ResNet101</td>
    <td>Image Recognition</td>
    <td>Unstructured</td>
    <td>Magnitude</td>
    <td><a href="./pytorch/image_recognition/torchvision_models/pruning/magnitude/eager">eager</a></td>
  </tr>
  <tr>
    <td>BERT large</td>
    <td>Natural Language Processing</td>
    <td>Structured (2x1)</td>
    <td>Group Lasso</td>
    <td><a href="./pytorch/nlp/huggingface_models/question-answering/pruning/group_lasso/eager">eager</a></td>
  </tr>
  <tr>
    <td>Intel/bert-base-uncased-sparse-70-unstructured</td>
    <td>Natural Language Processing (question-answering)</td>
    <td>Unstructured</td>
    <td>Pattern Lock</td>
    <td><a href="./pytorch/nlp/huggingface_models/question-answering/pruning/pattern_lock/eager">eager</a></td>
  </tr>
  <tr>
    <td>bert-base-uncased</td>
    <td>Natural Language Processing</td>
    <td>Structured (Filter/Channel-wise)</td>
    <td>Gradient Sensitivity</td>
    <td><a href="./pytorch/nlp/huggingface_models/text-classification/pruning/gradient_sensitivity/eager">eager</a></td>
  </tr>
  <tr>
    <td>DistilBERT</td>
    <td>Natural Language Processing</td>
    <td>Unstructured</td>
    <td>Magnitude</td>
    <td><a href="./pytorch/nlp/huggingface_models/text-classification/pruning/magnitude/eager">eager</a></td>
  </tr>
  <tr>
    <td>Intel/bert-base-uncased-sparse-70-unstructured</td>
    <td>Natural Language Processing (text-classification)</td>
    <td>Unstructured</td>
    <td>Pattern Lock</td>
    <td><a href="./pytorch/nlp/huggingface_models/text-classification/pruning/pattern_lock/eager">eager</a></td>
  </tr>
  <tr>
    <td>Bert-mini</td>
    <td>Natural Language Processing (text classification)</td>
    <td>Structured (4x1, 2in4), Unstructured</td>
    <td>Snip-momentum</td>
    <td><a href="./pytorch/nlp/huggingface_models/text-classification/pruning/pytorch_pruner/eager">eager</a></td>
  </tr>
  <tr>
    <td>Bert-mini</td>
    <td>Natural Language Processing (question answering)</td>
    <td>Structured (4x1, 2in4), Unstructured</td>
    <td>Snip-momentum</td>
    <td><a href="./pytorch/nlp/huggingface_models/question-answering/pruning/pytorch_pruner/eager">eager</a></td>
  </tr>
</tbody>
</table></div>
<div class="section" id="id3">
<h2>Distillation<a class="headerlink" href="#id3" title="Permalink to this headline">¶</a></h2>
<table>
<thead>
  <tr>
    <th>Student Model</th>
    <th>Teacher Model</th>
    <th>Domain</th>
    <th>Examples</th>
  </tr>
</thead>
<tbody>
  <tr>
    <td>CNN-2</td>
    <td>CNN-10</td>
    <td>Image Recognition</td>
    <td><a href="./pytorch/image_recognition/CNN-2/distillation/eager">eager</a></td>
  </tr>
  <tr>
    <td>MobileNet V2-0.35</td>
    <td>WideResNet40-2</td>
    <td>Image Recognition</td>
    <td><a href="./pytorch/image_recognition/MobileNetV2-0.35/distillation/eager">eager</a></td>
  </tr>
  <tr>
    <td>ResNet18|ResNet34|ResNet50|ResNet101</td>
    <td>ResNet18|ResNet34|ResNet50|ResNet101</td>
    <td>Image Recognition</td>
    <td><a href="./pytorch/image_recognition/torchvision_models/distillation/eager">eager</a></td>
  </tr>
  <tr>
    <td>VGG-8</td>
    <td>VGG-13</td>
    <td>Image Recognition</td>
    <td><a href="./pytorch/image_recognition/VGG-8/distillation/eager">eager</a></td>
  </tr>
  <tr>
    <td>BlendCNN</td>
    <td>BERT base</td>
    <td>Natural Language Processing</td>
    <td><a href="./pytorch/nlp/blendcnn/distillation/eager">eager</a></td>
  </tr>
  <tr>
    <td>distilbert-base-uncased</td>
    <td>csarron/bert-base-uncased-squad-v1</td>
    <td>Natural Language Processing</td>
    <td><a href="./pytorch/nlp/huggingface_models/question-answering/distillation/eager">eager</a></td>
  </tr>
  <tr>
    <td>BiLSTM</td>
    <td>textattack/roberta-base-SST-2</td>
    <td>Natural Language Processing</td>
    <td><a href="./pytorch/nlp/huggingface_models/text-classification/distillation/eager">eager</a></td>
  </tr>
  <tr>
    <td>huawei-noah/TinyBERT_General_4L_312D</td>
    <td>blackbird/bert-base-uncased-MNLI-v1</td>
    <td>Natural Language Processing</td>
    <td><a href="./pytorch/nlp/huggingface_models/text-classification/distillation/eager">eager</a></td>
  </tr>
  <tr>
    <td>nreimers</td>
    <td>textattack/bert-base-uncased-QQP</td>
    <td>Natural Language Processing</td>
    <td><a href="./pytorch/nlp/huggingface_models/text-classification/distillation/eager">eager</a></td>
  </tr>
  <tr>
    <td>distilroberta-base</td>
    <td>howey/roberta-large-cola</td>
    <td>Natural Language Processing</td>
    <td><a href="./pytorch/nlp/huggingface_models/text-classification/distillation/eager">eager</a></td>
  </tr>
</tbody>
</table></div>
<div class="section" id="orchestration">
<h2>Orchestration<a class="headerlink" href="#orchestration" title="Permalink to this headline">¶</a></h2>
<table>
<thead>
  <tr>
    <th>Model</th>
    <th>Domain</th>
    <th>Approach</th>
    <th>Examples</th>
  </tr>
</thead>
<tbody>
  <tr>
    <td>ResNet50</td>
    <td>Image Recognition</td>
    <td>Multi-shot: Pruning and PTQ<br></td>
    <td><a href="./pytorch/image_recognition/torchvision_models/optimization_pipeline/prune_and_ptq/eager">link</a></td>
  </tr>
  <tr>
    <td>ResNet50</td>
    <td>Image Recognition</td>
    <td>One-shot: QAT during Pruning<br></td>
    <td><a href="./pytorch/image_recognition/torchvision_models/optimization_pipeline/qat_during_prune/eager">link</a></td>
  </tr>
  <tr>
    <td>Intel/bert-base-uncased-sparse-90-unstructured-pruneofa</td>
    <td>Natural Language Processing (question-answering)</td>
    <td>One-shot: Pruning, Distillation and QAT<br></td>
    <td><a href="./pytorch/nlp/huggingface_models/question-answering/optimization_pipeline/prune_once_for_all/fx">link</a></td>
  </tr>
  <tr>
    <td>Intel/bert-base-uncased-sparse-90-unstructured-pruneofa</td>
    <td>Natural Language Processing (text-classification)</td>
    <td>One-shot: Pruning, Distillation and QAT<br></td>
    <td><a href="./pytorch/nlp/huggingface_models/text-classification/optimization_pipeline/prune_once_for_all/fx">link</a></td>
  </tr>
</tbody>
</table></div>
</div>
<div class="section" id="onnx-runtime-examples">
<h1>ONNX Runtime Examples<a class="headerlink" href="#onnx-runtime-examples" title="Permalink to this headline">¶</a></h1>
<div class="section" id="id4">
<h2>Quantization<a class="headerlink" href="#id4" title="Permalink to this headline">¶</a></h2>
<table>
<thead>
  <tr>
    <th>Model</th>
    <th>Domain</th>
    <th>Approach </th>
    <th>Examples</th>
  </tr>
</thead>
<tbody>
  <tr>
    <td>ResNet50 V1.5</td>
    <td>Image Recognition</td>
    <td>Post-Training Static Quantization</td>
    <td><a href="./onnxrt/image_recognition/resnet50/quantization/ptq">qlinearops</a> / <a href="./onnxrt/image_recognition/resnet50/quantization/ptq">qdq</a></td>
  </tr>
  <tr>
    <td>ResNet50 V1.5 MLPerf</td>
    <td>Image Recognition</td>
    <td>Post-Training Static Quantization</td>
    <td><a href="./onnxrt/image_recognition/resnet50/quantization/ptq">qlinearops</a> / <a href="./onnxrt/image_recognition/resnet50/quantization/ptq">qdq</a></td>
  </tr>
  <tr>
    <td>VGG16</td>
    <td>Image Recognition</td>
    <td>Post-Training Static Quantization</td>
    <td><a href="./onnxrt/image_recognition/vgg16/quantization/ptq">qlinearops</a> / <a href="./onnxrt/image_recognition/vgg16/quantization/ptq">qdq</a></td>
  </tr>
  <tr>
    <td>MobileNet V2</td>
    <td>Image Recognition</td>
    <td>Post-Training Static Quantization</td>
    <td><a href="./onnxrt/image_recognition/mobilenet_v2/quantization/ptq">qlinearops</a> / <a href="./onnxrt/image_recognition/mobilenet_v2/quantization/ptq">qdq</a></td>
  </tr>
  <tr>
    <td>MobileNet V3 MLPerf</td>
    <td>Image Recognition</td>
    <td>Post-Training Static Quantization</td>
    <td><a href="./onnxrt/image_recognition/mobilenet_v3/quantization/ptq">qlinearops</a> / <a href="./onnxrt/image_recognition/mobilenet_v3/quantization/ptq">qdq</a></td>
  </tr>
  <tr>
    <td>AlexNet</td>
    <td>Image Recognition</td>
    <td>Post-Training Static Quantization</td>
    <td><a href="./onnxrt/image_recognition/onnx_model_zoo/alexnet/quantization/ptq">qlinearops</a> / <a href="./onnxrt/image_recognition/onnx_model_zoo/alexnet/quantization/ptq">qdq</a></td>
  </tr>
  <tr>
    <td>CaffeNet</td>
    <td>Image Recognition</td>
    <td>Post-Training Static Quantization</td>
    <td><a href="./onnxrt/image_recognition/onnx_model_zoo/caffenet/quantization/ptq">qlinearops</a> / <a href="./onnxrt/image_recognition/onnx_model_zoo/caffenet/quantization/ptq">qdq</a></td>
  </tr>
  <tr>
    <td>DenseNet</td>
    <td>Image Recognition</td>
    <td>Post-Training Static Quantization</td>
    <td><a href="./onnxrt/image_recognition/onnx_model_zoo/densenet/quantization/ptq">qlinearops</a></td>
  </tr>
  <tr>
    <td>EfficientNet</td>
    <td>Image Recognition</td>
    <td>Post-Training Static Quantization</td>
    <td><a href="./onnxrt/image_recognition/onnx_model_zoo/efficientnet/quantization/ptq">qlinearops</a> / <a href="./onnxrt/image_recognition/onnx_model_zoo/efficientnet/quantization/ptq">qdq</a></td>
  </tr>
  <tr>
    <td>FCN</td>
    <td>Image Recognition</td>
    <td>Post-Training Static Quantization</td>
    <td><a href="./onnxrt/image_recognition/onnx_model_zoo/fcn/quantization/ptq">qlinearops</a> / <a href="./onnxrt/image_recognition/onnx_model_zoo/fcn/quantization/ptq">qdq</a></td>
  </tr>
  <tr>
    <td>GoogleNet</td>
    <td>Image Recognition</td>
    <td>Post-Training Static Quantization</td>
    <td><a href="./onnxrt/image_recognition/onnx_model_zoo/googlenet/quantization/ptq">qlinearops</a> / <a href="./onnxrt/image_recognition/onnx_model_zoo/googlenet/quantization/ptq">qdq</a></td>
  </tr>
  <tr>
    <td>Inception V1</td>
    <td>Image Recognition</td>
    <td>Post-Training Static Quantization</td>
    <td><a href="./onnxrt/image_recognition/onnx_model_zoo/inception/quantization/ptq">qlinearops</a> / <a href="./onnxrt/image_recognition/onnx_model_zoo/inception/quantization/ptq">qdq</a></td>
  </tr>
  <tr>
    <td>MNIST</td>
    <td>Image Recognition</td>
    <td>Post-Training Static Quantization</td>
    <td><a href="./onnxrt/image_recognition/onnx_model_zoo/mnist/quantization/ptq">qlinearops</a></td>
  </tr>
  <tr>
    <td>MobileNet V2 (ONNX Model Zoo)</td>
    <td>Image Recognition</td>
    <td>Post-Training Static Quantization</td>
    <td><a href="./onnxrt/image_recognition/onnx_model_zoo/mobilenet/quantization/ptq">qlinearops</a> / <a href="./onnxrt/image_recognition/onnx_model_zoo/mobilenet/quantization/ptq">qdq</a></td>
  </tr>
  <tr>
    <td>ResNet50 V1.5 (ONNX Model Zoo)</td>
    <td>Image Recognition</td>
    <td>Post-Training Static Quantization</td>
    <td><a href="./onnxrt/image_recognition/onnx_model_zoo/resnet50/quantization/ptq">qlinearops</a> / <a href="./onnxrt/image_recognition/onnx_model_zoo/resnet50/quantization/ptq">qdq</a></td>
  </tr>
  <tr>
    <td>ShuffleNet V2</td>
    <td>Image Recognition</td>
    <td>Post-Training Static Quantization</td>
    <td><a href="./onnxrt/image_recognition/onnx_model_zoo/shufflenet/quantization/ptq">qlinearops</a> / <a href="./onnxrt/image_recognition/onnx_model_zoo/shufflenet/quantization/ptq">qdq</a></td>
  </tr>
  <tr>
    <td>SqueezeNet</td>
    <td>Image Recognition</td>
    <td>Post-Training Static Quantization</td>
    <td><a href="./onnxrt/image_recognition/onnx_model_zoo/squeezenet/quantization/ptq">qlinearops</a> / <a href="./onnxrt/image_recognition/onnx_model_zoo/squeezenet/quantization/ptq">qdq</a></td>
  </tr>
  <tr>
    <td>VGG16 (ONNX Model Zoo)</td>
    <td>Image Recognition</td>
    <td>Post-Training Static Quantization</td>
    <td><a href="./onnxrt/image_recognition/onnx_model_zoo/vgg16/quantization/ptq">qlinearops</a> / <a href="./onnxrt/image_recognition/onnx_model_zoo/vgg16/quantization/ptq">qdq</a></td>
  </tr>
  <tr>
    <td>ZFNet</td>
    <td>Image Recognition</td>
    <td>Post-Training Static Quantization</td>
    <td><a href="./onnxrt/image_recognition/onnx_model_zoo/zfnet/quantization/ptq">qlinearops</a> / <a href="./onnxrt/image_recognition/onnx_model_zoo/zfnet/quantization/ptq">qdq</a></td>
  </tr>
  <tr>
    <td>ArcFace</td>
    <td>Image Recognition</td>
    <td>Post-Training Static Quantization</td>
    <td><a href="./onnxrt/image_recognition/onnx_model_zoo/arcface/quantization/ptq">qlinearops</a></td>
  </tr>
  <tr>
    <td>BERT base MRPC</td>
    <td>Natural Language Processing</td>
    <td>Post-Training Static Quantization</td>
    <td><a href="./onnxrt/language_translation/bert/quantization/ptq">integerops</a> / <a href="./onnxrt/language_translation/bert/quantization/ptq">qdq</a></td>
  </tr>
  <tr>
    <td>BERT base MRPC</td>
    <td>Natural Language Processing</td>
    <td>Post-Training Dynamic Quantization</td>
    <td><a href="./onnxrt/language_translation/bert/quantization/ptq">integerops</a></td>
  </tr>
  <tr>
    <td>DistilBERT base MRPC</td>
    <td>Natural Language Processing</td>
    <td>Post-Training Dynamic / Static Quantization</td>
    <td><a href="./onnxrt/language_translation/distilbert/quantization/ptq">integerops</a> / <a href="./onnxrt/language_translation/distilbert/quantization/ptq">qdq</a></td>
  </tr>
  <tr>
    <td>Mobile bert MRPC</td>
    <td>Natural Language Processing</td>
    <td>Post-Training Dynamic / Static Quantization</td>
    <td><a href="./onnxrt/language_translation/mobilebert/quantization/ptq">integerops</a> / <a href="./onnxrt/language_translation/mobilebert/quantization/ptq">qdq</a></td>
  </tr>
  <tr>
    <td>Roberta base MRPC</td>
    <td>Natural Language Processing</td>
    <td>Post-Training Dynamic / Static Quantization</td>
    <td><a href="./onnxrt/language_translation/roberta/quantization/ptq">integerops</a> / <a href="./onnxrt/language_translation/roberta/quantization/ptq">qdq</a></td>
  </tr>
  <tr>
    <td>BERT SQuAD</td>
    <td>Natural Language Processing</td>
    <td>Post-Training Dynamic / Static Quantization</td>
    <td><a href="./onnxrt/language_translation/onnx_model_zoo/bert-squad/quantization/ptq">integerops</a> / <a href="./onnxrt/language_translation/onnx_model_zoo/bert-squad/quantization/ptq">qdq</a></td>
  </tr>
  <tr>
    <td>GPT2 lm head WikiText</td>
    <td>Natural Language Processing</td>
    <td>Post-Training Dynamic Quantization</td>
    <td><a href="./onnxrt/language_translation/onnx_model_zoo/gpt2/quantization/ptq">integerops</a></td>
  </tr>
  <tr>
    <td>MobileBERT SQuAD MLPerf</td>
    <td>Natural Language Processing</td>
    <td>Post-Training Dynamic / Static Quantization</td>
    <td><a href="./onnxrt/language_translation/onnx_model_zoo/mobilebert/quantization/ptq">integerops</a> / <a href="./onnxrt/language_translation/onnx_model_zoo/mobilebert/quantization/ptq">qdq</a></td>
  </tr>
  <tr>
    <td>BiDAF</td>
    <td>Natural Language Processing</td>
    <td>Post-Training Dynamic Quantization</td>
    <td><a href="./onnxrt/language_translation/onnx_model_zoo/BiDAF/quantization/ptq">integerops</a></td>
  </tr>
  <tr>
    <td>SSD MobileNet V1</td>
    <td>Object Detection</td>
    <td>Post-Training Static Quantization</td>
    <td><a href="./onnxrt/object_detection/ssd_mobilenet_v1/quantization/ptq">qlinearops</a> / <a href="./onnxrt/object_detection/ssd_mobilenet_v1/quantization/ptq">qdq</a></td>
  </tr>
  <tr>
    <td>SSD MobileNet V2</td>
    <td>Object Detection</td>
    <td>Post-Training Static Quantization</td>
    <td><a href="./onnxrt/object_detection/ssd_mobilenet_v2/quantization/ptq">qlinearops</a> / <a href="./onnxrt/object_detection/ssd_mobilenet_v2/quantization/ptq">qdq</a></td>
  </tr>
  <tr>
    <td>SSD MobileNet V1 (ONNX Model Zoo)</td>
    <td>Object Detection</td>
    <td>Post-Training Static Quantization</td>
    <td><a href="./onnxrt/object_detection/onnx_model_zoo/ssd_mobilenet_v1/quantization/ptq">qlinearops</a> / <a href="./onnxrt/object_detection/onnx_model_zoo/ssd_mobilenet_v1/quantization/ptq">qdq</a></td>
  </tr>
  <tr>
    <td>DUC</td>
    <td>Object Detection</td>
    <td>Post-Training Static Quantization</td>
    <td><a href="./onnxrt/object_detection/onnx_model_zoo/DUC/quantization/ptq">qlinearops</a></td>
  </tr>
  <tr>
    <td>Faster R-CNN</td>
    <td>Object Detection</td>
    <td>Post-Training Static Quantization</td>
    <td><a href="./onnxrt/object_detection/onnx_model_zoo/faster_rcnn/quantization/ptq">qlinearops</a> / <a href="./onnxrt/object_detection/onnx_model_zoo/faster_rcnn/quantization/ptq">qdq</a></td>
  </tr>
  <tr>
    <td>Mask R-CNN</td>
    <td>Object Detection</td>
    <td>Post-Training Static Quantization</td>
    <td><a href="./onnxrt/object_detection/onnx_model_zoo/mask_rcnn/quantization/ptq">qlinearops</a> / <a href="./onnxrt/object_detection/onnx_model_zoo/mask_rcnn/quantization/ptq">qdq</a></td>
  </tr>
  <tr>
    <td>SSD</td>
    <td>Object Detection</td>
    <td>Post-Training Static Quantization</td>
    <td><a href="./onnxrt/object_detection/onnx_model_zoo/ssd/quantization/ptq">qlinearops</a> / <a href="./onnxrt/object_detection/onnx_model_zoo/ssd/quantization/ptq">qdq</a></td>
  </tr>
  <tr>
    <td>Tiny YOLOv3</td>
    <td>Object Detection</td>
    <td>Post-Training Static Quantization</td>
    <td><a href="./onnxrt/object_detection/onnx_model_zoo/tiny_yolov3/quantization/ptq">qlinearops</a></td>
  </tr>
  <tr>
    <td>YOLOv3</td>
    <td>Object Detection</td>
    <td>Post-Training Static Quantization</td>
    <td><a href="./onnxrt/object_detection/onnx_model_zoo/yolov3/quantization/ptq">qlinearops</a></td>
  </tr>
  <tr>
    <td>YOLOv4</td>
    <td>Object Detection</td>
    <td>Post-Training Static Quantization</td>
    <td><a href="./onnxrt/object_detection/onnx_model_zoo/yolov4/quantization/ptq">qlinearops</a></td>
  </tr>
  <tr>
    <td>Emotion FERPlus</td>
    <td>Body Analysis</td>
    <td>Post-Training Static Quantization</td>
    <td><a href="./onnxrt/body_analysis/onnx_model_zoo/emotion_ferplus/quantization/ptq">qlinearops</a></td>
  </tr>
  <tr>
    <td>Ultra Face</td>
    <td>Body Analysis</td>
    <td>Post-Training Static Quantization</td>
    <td><a href="./onnxrt/body_analysis/onnx_model_zoo/ultraface/quantization/ptq">qlinearops</a></td>
  </tr>
</tbody>
</table></div>
</div>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, Intel® Neural Compressor.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>