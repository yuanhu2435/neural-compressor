<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Step-by-Step &mdash; Intel® Neural Compressor  documentation</title><link rel="stylesheet" href="../../../../../../../../_static/css/theme.css" type="text/css" />
    <link rel="stylesheet" href="../../../../../../../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../../../../../../../_static/custom.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../../../../../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  <script id="documentation_options" data-url_root="../../../../../../../../" src="../../../../../../../../_static/documentation_options.js"></script>
        <script src="../../../../../../../../_static/jquery.js"></script>
        <script src="../../../../../../../../_static/underscore.js"></script>
        <script src="../../../../../../../../_static/doctools.js"></script>
    <script src="../../../../../../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../../../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../../../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../../../../../../../index.html" class="icon icon-home"> Intel® Neural Compressor
          </a>
              <div class="version">
                1.14.2
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../../README.html">Intel® Neural Compressor</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../../docs/examples_readme.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../../api-documentation/apis.html">APIs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../../docs/doclist.html">Developer Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../../docs/releases_info.html">Release</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../../docs/contributions.html">Contribution Guidelines</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../../docs/legal_information.html">Legal Information</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/intel/neural-compressor">Intel® Neural Compressor repository</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../../../../../index.html">Intel® Neural Compressor</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../../../../../../index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Step-by-Step</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../../../../../../../_sources/examples/pytorch/image_recognition/torchvision_models/quantization/ptq/cpu/ipex/README.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <div class="section" id="step-by-step">
<h1>Step-by-Step<a class="headerlink" href="#step-by-step" title="Permalink to this headline">¶</a></h1>
<p>This document describes the step-by-step instructions for reproducing PyTorch ResNet50/ResNet18/ResNet101 tuning results with Intel® Neural Compressor.</p>
</div>
<div class="section" id="prerequisite">
<h1>Prerequisite<a class="headerlink" href="#prerequisite" title="Permalink to this headline">¶</a></h1>
<div class="section" id="installation">
<h2>1. Installation<a class="headerlink" href="#installation" title="Permalink to this headline">¶</a></h2>
<p>We verified examples with IPEX backend on Python 3.8, recommended.</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span> examples/pytorch/image_recognition/torchvision_models/quantization/ptq/cpu/ipex
pip install -r requirements.txt
</pre></div>
</div>
</div>
<div class="section" id="install-pytorch-and-intel-pytorch-extension">
<h2>2. Install pytorch and intel-pytorch-extension<a class="headerlink" href="#install-pytorch-and-intel-pytorch-extension" title="Permalink to this headline">¶</a></h2>
<p>refer <a class="reference external" href="https://github.com/intel/intel-extension-for-pytorch/tree/v1.8.0">intel/intel-extension-for-pytorch at icx (github.com)</a></p>
<ol>
<li><p>install PyTorch and TorchVision</p>
<p>refer <a class="reference external" href="https://pytorch.org/get-started/locally/">PyTorch install</a></p>
<div class="highlight-shell position-relative notranslate"><div class="highlight"><pre><span></span> pip install requirements.txt
</pre></div>
</div>
</li>
<li><p>Get  Intel® Extension for PyTorch* source and install</p>
<blockquote>
<div><p><strong>Note</strong></p>
<p>GCC9 compiler is recommended</p>
</div></blockquote>
<div class="highlight-shell position-relative notranslate"><div class="highlight"><pre><span></span>python -m pip install intel_extension_for_pytorch -f https://software.intel.com/ipex-whl-stable
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># build from source for IPEX 1.12</span>
 <span class="n">git</span> <span class="n">clone</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">github</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">intel</span><span class="o">/</span><span class="n">intel</span><span class="o">-</span><span class="n">extension</span><span class="o">-</span><span class="k">for</span><span class="o">-</span><span class="n">pytorch</span><span class="o">/</span>
 <span class="n">cd</span> <span class="n">intel</span><span class="o">-</span><span class="n">extension</span><span class="o">-</span><span class="k">for</span><span class="o">-</span><span class="n">pytorch</span>
 <span class="n">git</span> <span class="n">submodule</span> <span class="n">sync</span> <span class="o">&amp;&amp;</span> <span class="n">git</span> <span class="n">submodule</span> <span class="n">update</span> <span class="o">--</span><span class="n">init</span> <span class="o">--</span><span class="n">recursive</span>
 <span class="n">git</span> <span class="n">checkout</span> <span class="mi">1279</span><span class="n">c5824f1bcb61cd8990f4148abcadf3f214a4</span>
 <span class="n">git</span> <span class="n">apply</span> <span class="o">../</span><span class="n">patch</span><span class="o">.</span><span class="n">patch</span>
 <span class="n">python</span> <span class="n">setup</span><span class="o">.</span><span class="n">py</span> <span class="n">install</span>
</pre></div>
</div>
<blockquote>
<div><p>Note: Intel® Extension for PyTorch* has PyTorch version &gt; requirement. Please check more detailed information via &gt; the URL below.</p>
<p>GCC9 compiler is recommended</p>
<p>Support IPEX version &gt;= 1.8.0, 1.12.0 version need build from source and apply patch.</p>
</div></blockquote>
</li>
</ol>
</div>
<div class="section" id="prepare-dataset">
<h2>3. Prepare Dataset<a class="headerlink" href="#prepare-dataset" title="Permalink to this headline">¶</a></h2>
<p>Download <a class="reference external" href="http://www.image-net.org/">ImageNet</a> Raw image to dir: /path/to/imagenet.  The dir include below folder:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>ls /path/to/imagenet
train  val
</pre></div>
</div>
</div>
</div>
<div class="section" id="run">
<h1>Run<a class="headerlink" href="#run" title="Permalink to this headline">¶</a></h1>
<div class="section" id="resnet18-with-intel-pytorch-extension">
<h2>1. ResNet18 With Intel PyTorch Extension<a class="headerlink" href="#resnet18-with-intel-pytorch-extension" title="Permalink to this headline">¶</a></h2>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>python main.py -t -a resnet18 --ipex --pretrained /path/to/imagenet
</pre></div>
</div>
<p>or</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>bash run_tuning.sh --topology<span class="o">=</span>resnet18_ipex --dataset_location<span class="o">=</span>/path/to/imagenet
bash run_benchmark.sh --topology<span class="o">=</span>resnet18_ipex --dataset_location<span class="o">=</span>/path/to/imagenet --mode<span class="o">=</span>benchmark/accuracy --int8<span class="o">=</span>true/false
</pre></div>
</div>
</div>
<div class="section" id="resnet50-with-intel-pytorch-extension">
<h2>2. ResNet50 With Intel PyTorch Extension<a class="headerlink" href="#resnet50-with-intel-pytorch-extension" title="Permalink to this headline">¶</a></h2>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>python main.py -t -a resnet50 --ipex --pretrained /path/to/imagenet
</pre></div>
</div>
<p>or</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>bash run_tuning.sh --topology<span class="o">=</span>resnet50_ipex --dataset_location<span class="o">=</span>/path/to/imagenet
bash run_benchmark.sh --topology<span class="o">=</span>resnet50_ipex --dataset_location<span class="o">=</span>/path/to/imagenet --mode<span class="o">=</span>benchmark/accuracy --int8<span class="o">=</span>true/false
</pre></div>
</div>
</div>
<div class="section" id="resnext101-32x16d-with-intel-pytorch-extension">
<h2>3. ResNext101_32x16d With Intel PyTorch Extension<a class="headerlink" href="#resnext101-32x16d-with-intel-pytorch-extension" title="Permalink to this headline">¶</a></h2>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>python main.py -t -a resnext101_32x16d_wsl --hub --ipex --pretrained /path/to/imagenet
</pre></div>
</div>
<p>or</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>bash run_tuning.sh --topology<span class="o">=</span>resnext101_32x16d_wsl_ipex --dataset_location<span class="o">=</span>/path/to/imagenet
bash run_benchmark.sh --topology<span class="o">=</span>resnext101_32x16d_wsl_ipex --dataset_location<span class="o">=</span>/path/to/imagenet --mode<span class="o">=</span>benchmark/accuracy --int8<span class="o">=</span>true/false
</pre></div>
</div>
</div>
</div>
<div class="section" id="saving-model">
<h1>Saving model:<a class="headerlink" href="#saving-model" title="Permalink to this headline">¶</a></h1>
<ul class="simple">
<li><p>Saving model:
After tuning with Neural Compressor, we can get neural_compressor.model:</p></li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">neural_compressor.experimental</span> <span class="k">import</span> <span class="n">Quantization</span><span class="p">,</span> <span class="n">common</span>
<span class="n">quantizer</span> <span class="o">=</span> <span class="n">Quantization</span><span class="p">(</span><span class="s2">&quot;./conf.yaml&quot;</span><span class="p">)</span>
<span class="n">quantizer</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">common</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="n">nc_model</span> <span class="o">=</span> <span class="n">quantizer</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
</pre></div>
</div>
<p>Here, nc_model is Neural Compressor model class, so it has “save” API:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">nc_model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;Path_to_save_configure_file&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>Please refer to <a class="reference external" href="https://github.com/intel/neural-compressor/blob/a08adb5df2b40cf083eebad4593c4b07ab7476a2/examples/pytorch/image_recognition/torchvision_models/quantization/ptq/cpu/ipex/./main.py">Sample code</a>.</p>
</div>
<div class="section" id="examples-of-enabling-neural-compressor-auto-tuning-on-pytorch-resnet">
<h1>Examples of enabling Neural Compressor auto tuning on PyTorch ResNet<a class="headerlink" href="#examples-of-enabling-neural-compressor-auto-tuning-on-pytorch-resnet" title="Permalink to this headline">¶</a></h1>
<p>This is a tutorial of how to enable a PyTorch classification model with Neural Compressor.</p>
</div>
<div class="section" id="user-code-analysis">
<h1>User Code Analysis<a class="headerlink" href="#user-code-analysis" title="Permalink to this headline">¶</a></h1>
<p>Neural Compressor supports three usages:</p>
<ol class="simple">
<li><p>User only provide fp32 “model”, and configure calibration dataset, evaluation dataset and metric in model-specific yaml config file.</p></li>
<li><p>User provide fp32 “model”, calibration dataset “q_dataloader” and evaluation dataset “eval_dataloader”, and configure metric in tuning.metric field of model-specific yaml config file.</p></li>
<li><p>User specifies fp32 “model”, calibration dataset “q_dataloader” and a custom “eval_func” which encapsulates the evaluation dataset and metric by itself.</p></li>
</ol>
<p>As ResNet18/50/101 series are typical classification models, use Top-K as metric which is built-in supported by Neural Compressor. So here we integrate PyTorch ResNet with Neural Compressor by the first use case for simplicity.</p>
<div class="section" id="write-yaml-config-file">
<h2>Write Yaml Config File<a class="headerlink" href="#write-yaml-config-file" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>In examples directory, there is a template.yaml. We could remove most of items and only     keep mandatory item for tuning.

```yaml
model:
  name: imagenet_ptq
  framework: pytorch_ipex

quantization:
  calibration:
    sampling_size: 300
    dataloader:
      dataset:
        ImageFolder:
          root: /path/to/calibration/dataset
      transform:
        RandomResizedCrop:
          size: 224
        RandomHorizontalFlip:
        ToTensor:
        Normalize:
          mean: [0.485, 0.456, 0.406]
          std: [0.229, 0.224, 0.225]

evaluation:
  accuracy:
    metric:
      topk: 1
    dataloader:
      batch_size: 30
      dataset:
        ImageFolder:
          root: /path/to/evaluation/dataset
      transform:
        Resize:
          size: 256
        CenterCrop:
          size: 224
        ToTensor:
        Normalize:
          mean: [0.485, 0.456, 0.406]
          std: [0.229, 0.224, 0.225]
  performance:
    configs:
      cores_per_instance: 4
      num_of_instance: 7
    dataloader:
      batch_size: 1
      dataset:
        ImageFolder:
          root: /path/to/evaluation/dataset
      transform:
        Resize:
          size: 256
        CenterCrop:
          size: 224
        ToTensor:
        Normalize:
          mean: [0.485, 0.456, 0.406]
          std: [0.229, 0.224, 0.225]

tuning:
  accuracy_criterion:
    relative:  0.01
  exit_policy:
    timeout: 0
  random_seed: 9527

```

Here we choose topk built-in metric and set accuracy target as tolerating 0.01 relative     accuracy loss of baseline. The default tuning strategy is basic strategy. The timeout 0     means unlimited time for a tuning config meet accuracy target.
</pre></div>
</div>
</div>
<div class="section" id="prepare">
<h2>Prepare<a class="headerlink" href="#prepare" title="Permalink to this headline">¶</a></h2>
<p>The related code please refer to examples/pytorch/ipex/image_recognition/imagenet/cpu/ptq/main.py.</p>
</div>
<div class="section" id="tuning-with-intel-pytorch-extension">
<h2>Tuning With Intel PyTorch Extension<a class="headerlink" href="#tuning-with-intel-pytorch-extension" title="Permalink to this headline">¶</a></h2>
<p>Tuning With Neural Compressor</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>```python
  from neural_compressor.experimental import Quantization, common
  quantizer = Quantization(&quot;./conf_ipex.yaml&quot;)
  quantizer.model = common.Model(model)
  nc_model = quantizer.fit()
  nc_model.save(&quot;Path_to_save_configure_file&quot;)
```
</pre></div>
</div>
</div>
</div>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, Intel® Neural Compressor.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>