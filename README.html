<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Introduction to Intel® Neural Compressor &mdash; Intel® Neural Compressor  documentation</title><link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Tutorial" href="docs/tutorial.html" />
    <link rel="prev" title="Intel® Neural Compressor Documentation" href="index.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html" class="icon icon-home"> Intel® Neural Compressor
          </a>
              <div class="version">
                1.11
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Introduction to Intel® Neural Compressor</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#installation">Installation</a></li>
<li class="toctree-l2"><a class="reference internal" href="#getting-started">Getting Started</a></li>
<li class="toctree-l2"><a class="reference internal" href="#system-requirements">System Requirements</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#validated-software-environment">Validated Software Environment</a></li>
<li class="toctree-l3"><a class="reference internal" href="#validated-models">Validated Models</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#documentation">Documentation</a></li>
<li class="toctree-l2"><a class="reference internal" href="#selected-publications">Selected Publications</a></li>
<li class="toctree-l2"><a class="reference internal" href="#additional-content">Additional Content</a></li>
<li class="toctree-l2"><a class="reference internal" href="#hiring">Hiring</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="docs/tutorial.html">Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="examples_readme.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="api-documentation/apis.html">APIs</a></li>
<li class="toctree-l1"><a class="reference internal" href="docs/doclist.html">Developer Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="releases_info.html">Release</a></li>
<li class="toctree-l1"><a class="reference internal" href="contributions.html">Contribution Guidelines</a></li>
<li class="toctree-l1"><a class="reference internal" href="legal_information.html">Legal Information</a></li>
<li class="toctree-l1"><a class="reference internal" href="security_policy.html">Security Policy</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/intel/neural-compressor">Intel® Neural Compressor repository</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">Intel® Neural Compressor</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Introduction to Intel® Neural Compressor</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/README.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <div class="section" id="introduction-to-intel-neural-compressor">
<h1>Introduction to Intel® Neural Compressor<a class="headerlink" href="#introduction-to-intel-neural-compressor" title="Permalink to this headline">¶</a></h1>
<p>Intel® Neural Compressor (formerly known as Intel® Low Precision Optimization Tool) is an open-source Python library running on Intel CPUs and GPUs, which delivers unified interfaces across multiple deep learning frameworks for popular network compression technologies, such as quantization, pruning, knowledge distillation. This tool supports automatic accuracy-driven tuning strategies to help user quickly find out the best quantized model. It also implements different weight pruning algorithms to generate pruned model with predefined sparsity goal and supports knowledge distillation to distill the knowledge from the teacher model to the student model.
Intel® Neural Compressor has been one of the critical AI software components in <a class="reference external" href="https://software.intel.com/content/www/us/en/develop/tools/oneapi/ai-analytics-toolkit.html">Intel® oneAPI AI Analytics Toolkit</a>.</p>
<blockquote>
<div><p><strong>Note</strong>
GPU support is under development.</p>
</div></blockquote>
<p><strong>Visit the Intel® Neural Compressor online document website at: <a class="reference external" href="https://intel.github.io/neural-compressor">https://intel.github.io/neural-compressor</a>.</strong></p>
<div class="section" id="installation">
<h2>Installation<a class="headerlink" href="#installation" title="Permalink to this headline">¶</a></h2>
<p><strong>Prerequisites</strong></p>
<ul class="simple">
<li><p>Python version: 3.7 or 3.8 or 3.9 or 3.10</p></li>
</ul>
<p><strong>Install on Linux</strong></p>
<div class="highlight-Shell notranslate"><div class="highlight"><pre><span></span><span class="c1"># install stable version from pip</span>
pip install neural-compressor

<span class="c1"># install nightly version from pip</span>
pip install -i https://test.pypi.org/simple/ neural-compressor

<span class="c1"># install stable version from from conda</span>
conda install neural-compressor -c conda-forge -c intel 
</pre></div>
</div>
<p>More installation methods can be found at <a class="reference internal" href="docs/installation_guide.html"><span class="doc">Installation Guide</span></a>.</p>
</div>
<div class="section" id="getting-started">
<h2>Getting Started<a class="headerlink" href="#getting-started" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Quantization with Python API</p></li>
</ul>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="c1"># A TensorFlow Example</span>
pip install tensorflow
<span class="c1"># Prepare fp32 model</span>
wget https://storage.googleapis.com/intel-optimized-tensorflow/models/v1_6/mobilenet_v1_1.0_224_frozen.pb
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="kn">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">neural_compressor.experimental</span> <span class="kn">import</span> <span class="n">Quantization</span><span class="p">,</span> <span class="n">common</span>
<span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v1</span><span class="o">.</span><span class="n">disable_eager_execution</span><span class="p">()</span>
<span class="n">quantizer</span> <span class="o">=</span> <span class="n">Quantization</span><span class="p">()</span>
<span class="n">quantizer</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="s1">&#39;./mobilenet_v1_1.0_224_frozen.pb&#39;</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">quantizer</span><span class="o">.</span><span class="n">dataset</span><span class="p">(</span><span class="s1">&#39;dummy&#39;</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="n">quantizer</span><span class="o">.</span><span class="n">calib_dataloader</span> <span class="o">=</span> <span class="n">common</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
<span class="n">quantizer</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Quantization with <a class="reference internal" href="docs/bench.html"><span class="doc">GUI</span></a></p></li>
</ul>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="c1"># An ONNX Example</span>
pip install <span class="nv">onnx</span><span class="o">==</span><span class="m">1</span>.9.0 <span class="nv">onnxruntime</span><span class="o">==</span><span class="m">1</span>.10.0 onnxruntime-extensions
<span class="c1"># Prepare fp32 model</span>
wget https://github.com/onnx/models/blob/main/vision/classification/resnet/model/resnet50-v1-12.onnx
<span class="c1"># Start GUI</span>
inc_bench
</pre></div>
</div>
<a target="_blank" href="./docs/imgs/INC_GUI.gif">
  <img src="./docs/imgs/INC_GUI.gif" alt="Architecture">
</a></div>
<div class="section" id="system-requirements">
<h2>System Requirements<a class="headerlink" href="#system-requirements" title="Permalink to this headline">¶</a></h2>
<p>Intel® Neural Compressor supports systems based on <a class="reference external" href="https://en.wikipedia.org/wiki/X86-64">Intel 64 architecture or compatible processors</a>, specially optimized for the following CPUs:</p>
<ul class="simple">
<li><p>Intel Xeon Scalable processor (formerly Skylake, Cascade Lake, Cooper Lake, and Icelake)</p></li>
<li><p>Future Intel Xeon Scalable processor (code name Sapphire Rapids)</p></li>
</ul>
<div class="section" id="validated-software-environment">
<h3>Validated Software Environment<a class="headerlink" href="#validated-software-environment" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>OS version: CentOS 8.4, Ubuntu 20.04</p></li>
<li><p>Python version: 3.7, 3.8, 3.9, 3.10</p></li>
</ul>
<table class="docutils">
<thead>
  <tr>
    <th>Framework</th>
    <th>TensorFlow</th>
    <th>Intel TensorFlow</th>
    <th>PyTorch</th>
    <th>IPEX</th>
    <th>ONNX Runtime</th>
    <th>MXNet</th>
  </tr>
</thead>
<tbody>
  <tr align="center">
    <th>Version</th>
    <td class="tg-7zrl"><a href=https://github.com/tensorflow/tensorflow/tree/v2.8.0>2.8.0</a><br>
    <a href=https://github.com/tensorflow/tensorflow/tree/v2.7.0>2.7.0</a><br>
    <a href=https://github.com/tensorflow/tensorflow/tree/v2.6.2>2.6.2</a></td>
    <td class="tg-7zrl"><a href=https://github.com/Intel-tensorflow/tensorflow/tree/v2.8.0>2.8.0</a><br>
    <a href=https://github.com/Intel-tensorflow/tensorflow/tree/v2.7.0>2.7.0</a><br>
    <a href=https://github.com/Intel-tensorflow/tensorflow/tree/v1.15.0up3>1.15.0UP3</a></td>
    <td class="tg-7zrl"><a href=https://download.pytorch.org/whl/torch_stable.html>1.11.0+cpu</a><br>
    <a href=https://download.pytorch.org/whl/torch_stable.html>1.10.0+cpu</a><br>
    <a href=https://download.pytorch.org/whl/torch_stable.html>1.9.0+cpu</a></td>
    <td class="tg-7zrl"><a href=https://github.com/intel/intel-extension-for-pytorch/tree/v1.11.0>1.11.0</a><br>
    <a href=https://github.com/intel/intel-extension-for-pytorch/tree/v1.10.0>1.10.0</a><br>
    <a href=https://github.com/intel/intel-extension-for-pytorch/tree/v1.9.0>1.9.0</a></td>
    <td class="tg-7zrl"><a href=https://github.com/microsoft/onnxruntime/tree/v1.10.0>1.10.0</a><br>
    <a href=https://github.com/microsoft/onnxruntime/tree/v1.9.0>1.9.0</a><br>
    <a href=https://github.com/microsoft/onnxruntime/tree/v1.8.0>1.8.0</a></td>
    <td class="tg-7zrl"><a href=https://github.com/apache/incubator-mxnet/tree/1.8.0>1.8.0</a><br>
    <a href=https://github.com/apache/incubator-mxnet/tree/1.7.0>1.7.0</a><br>
    <a href=https://github.com/apache/incubator-mxnet/tree/1.6.0>1.6.0</a></td>
  </tr>
</tbody>
</table></div>
<div class="section" id="validated-models">
<h3>Validated Models<a class="headerlink" href="#validated-models" title="Permalink to this headline">¶</a></h3>
<p>Intel® Neural Compressor validated 420+ <a class="reference external" href="https://github.com/intel/neural-compressor/tree/130eefa3586b38df6c0ff78cc8807ae273f6a63f/./examples">examples</a> with performance speedup geomean 2.2x and up to 4.2x on VNNI while minimizing the accuracy loss.
More details for validated models are available <a class="reference internal" href="docs/validated_model_list.html"><span class="doc">here</span></a>.</p>
<a target="_blank" href="./docs/imgs/INC-release-data.png">
  <img src="./docs/imgs/INC-release-data.png" alt="Architecture" width=750 height=500>
</a></div>
</div>
<div class="section" id="documentation">
<h2>Documentation<a class="headerlink" href="#documentation" title="Permalink to this headline">¶</a></h2>
<table class="docutils">
  <thead>
  <tr>
    <th colspan="9">Overview</th>
  </tr>
  </thead>
  <tbody>
    <tr>
      <td colspan="3" align="center"><a href="docs/infrastructure.md">Infrastructure</a></td>
      <td colspan="2" align="center"><a href="docs/tutorial.md">Tutorial</a></td>
      <td colspan="2" align="center"><a href="./examples">Examples</a></td>
      <td colspan="1" align="center"><a href="docs/bench.md">GUI</a></td>
      <td colspan="1" align="center"><a href="docs/api-introduction.md">APIs</a></td>
    </tr>
    <tr>
      <td colspan="5" align="center"><a href="https://software.intel.com/content/www/us/en/develop/documentation/get-started-with-ai-linux/top.html">Intel oneAPI AI Analytics Toolkit</a></td>
      <td colspan="4" align="center"><a href="https://github.com/oneapi-src/oneAPI-samples/tree/master/AI-and-Analytics">AI and Analytics Samples</a></td>
    </tr>
  </tbody>
  <thead>
  <tr>
    <th colspan="9">Basic API</th>
  </tr>
  </thead>
  <tbody>
    <tr>
      <td colspan="2" align="center"><a href="docs/transform.md">Transform</a></td>
      <td colspan="2" align="center"><a href="docs/dataset.md">Dataset</a></td>
      <td colspan="2" align="center"><a href="docs/metric.md">Metric</a></td>
      <td colspan="3" align="center"><a href="docs/objective.md">Objective</a></td>
    </tr>
  </tbody>
  <thead>
    <tr>
      <th colspan="9">Deep Dive</th>
    </tr>
  </thead>
  <tbody>
    <tr>
        <td colspan="2" align="center"><a href="docs/Quantization.md">Quantization</a></td>
        <td colspan="1" align="center"><a href="docs/pruning.md">Pruning</a></td>
        <td colspan="3" align="center"><a href="docs/distillation.md">Knowledge Distillation</a></td>
        <td colspan="3" align="center"><a href="docs/mixed_precision.md">Mixed precision</a></td>
    </tr>
    <tr>
        <td colspan="2" align="center"><a href="docs/benchmark.md">Benchmarking</a></td>
        <td colspan="3" align="center"><a href="docs/distributed.md">Distributed Training</a></td>
        <td colspan="2" align="center"><a href="docs/model_conversion.md">Model Conversion</a></td>
        <td colspan="2" align="center"><a href="docs/tensorboard.md">TensorBoard</a></td>
    </tr>
  </tbody>
  <thead>
      <tr>
        <th colspan="9">Advanced Topics</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td colspan="5" align="center"><a href="docs/adaptor.md">Adaptor</a></td>
          <td colspan="4" align="center"><a href="docs/tuning_strategies.md">Strategy</a></td>
      </tr>
  </tbody>
</table></div>
<div class="section" id="selected-publications">
<h2>Selected Publications<a class="headerlink" href="#selected-publications" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p><a class="reference external" href="https://networkbuilders.intel.com/solutionslibrary/intel-deep-learning-boost-boost-network-security-ai-inference-performance-in-google-cloud-platform-gcp-technology-guide">Intel® Deep Learning Boost - Boost Network Security AI Inference Performance in Google Cloud Platform (GCP)</a> (Apr 2022)</p></li>
<li><p><a class="reference external" href="https://pytorch.org/ecosystem/">Intel® Neural Compressor joined PyTorch ecosystem tool </a> (Apr 2022)</p></li>
<li><p><a class="reference external" href="https://builders.intel.com/docs/networkbuilders/ai-technologies-unleash-ai-innovation-in-network-applications-solution-brief-1637303210.pdf">New instructions in the Intel® Xeon® Scalable processors combined with optimized software frameworks enable real-time AI within network workloads</a> (Feb 2022)</p></li>
<li><p><a class="reference external" href="https://community.intel.com/t5/Blogs/Tech-Innovation/Artificial-Intelligence-AI/Quantizing-ONNX-Models-using-Intel-Neural-Compressor/post/1355237">Quantizing ONNX Models using Intel® Neural Compressor</a> (Feb 2022)</p></li>
<li><p><a class="reference external" href="https://www.intel.com/content/www/us/en/developer/articles/technical/quantize-ai-by-oneapi-analytics-on-alibaba-cloud.html">Quantize AI Model by Intel® oneAPI AI Analytics Toolkit on Alibaba Cloud</a> (Feb 2022)</p></li>
</ul>
<blockquote>
<div><p>View the <a class="reference internal" href="docs/publication_list.html"><span class="doc">full publication list</span></a>.</p>
</div></blockquote>
</div>
<div class="section" id="additional-content">
<h2>Additional Content<a class="headerlink" href="#additional-content" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p><a class="reference internal" href="releases_info.html"><span class="doc">Release Information</span></a></p></li>
<li><p><a class="reference internal" href="contributions.html"><span class="doc">Contribution Guidelines</span></a></p></li>
<li><p><a class="reference internal" href="legal_information.html"><span class="doc">Legal Information</span></a></p></li>
<li><p><a class="reference internal" href="security_policy.html"><span class="doc">Security Policy</span></a></p></li>
<li><p><a class="reference external" href="https://intel.github.io/neural-compressor">Intel® Neural Compressor Website</a></p></li>
</ul>
</div>
<div class="section" id="hiring">
<h2>Hiring<a class="headerlink" href="#hiring" title="Permalink to this headline">¶</a></h2>
<p>We are hiring. Please send your resume to inc.maintainers&#64;intel.com if you have interests in model compression techniques.</p>
</div>
</div>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="index.html" class="btn btn-neutral float-left" title="Intel® Neural Compressor Documentation" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="docs/tutorial.html" class="btn btn-neutral float-right" title="Tutorial" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, Intel® Neural Compressor.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>